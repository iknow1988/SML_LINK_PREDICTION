{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import csv\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, auc\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTILITY FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving object\n",
    "def save_obj(obj,name):\n",
    "    with open('obj/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "#Load saved object file\n",
    "def load_obj(name):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "# Accuracy Report\n",
    "def check_results(predictions, classifications):\n",
    "    print(\"Accuracy:\")\n",
    "    print(accuracy_score(classifications,predictions))\n",
    "    print(classification_report(classifications,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pos = load_obj('df_train_pos')\n",
    "df_train_neg= load_obj('df_train_neg')\n",
    "df_test = load_obj('df_test')\n",
    "df_train_pos['label'] = 1\n",
    "df_train_neg['label'] = 0\n",
    "df_test['label'] =-1\n",
    "print(df_train_pos.shape, df_train_neg.shape,df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALCULATE ADDITIONAL FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_neg['aa'] = df_train_neg['aa'].replace(-123.0, .001)\n",
    "df_train_pos['aa'] = df_train_pos['aa'].replace(-123.0, .001)\n",
    "df_test['aa'] = df_test['aa'].replace(-123.0, .001)\n",
    "df_train_pos = df_train_pos.drop(['source', 'sink'], axis = 1)\n",
    "df_train_neg = df_train_neg.drop(['source', 'sink'], axis = 1)\n",
    "df_train_pos = df_train_pos.drop(['index'], axis = 1)\n",
    "df_train_neg = df_train_neg.drop(['index'], axis = 1)\n",
    "df_test = df_test.drop(['source', 'sink'], axis = 1)\n",
    "df_train_pos['label'] = 1\n",
    "df_train_neg['label'] = 0\n",
    "df_test['label'] = -1\n",
    "df_train_pos.isnull().values.any(), df_train_neg.isnull().values.any(), df_test.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pos['inDegreeRatio'] = df_train_pos.sink_inDegree/df_train_pos.source_inDegree\n",
    "df_train_neg['inDegreeRatio'] = df_train_neg.sink_inDegree/df_train_neg.source_inDegree\n",
    "df_test['inDegreeRatio'] = df_test.sink_inDegree/df_test.source_inDegree\n",
    "df_train_pos.isnull().values.any(), df_train_neg.isnull().values.any(), df_test.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pos['common_neighbors'] = df_train_pos.common_followees + df_train_pos.common_followers\n",
    "df_train_neg['common_neighbors'] = df_train_neg.common_followees + df_train_neg.common_followers\n",
    "df_test['common_neighbors'] = df_test.common_followees + df_test.common_followers\n",
    "df_train_pos.isnull().values.any(), df_train_neg.isnull().values.any(), df_test.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard IN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pos['jaccard_in'] = df_train_pos.common_followers/(df_train_pos.source_inDegree + df_train_pos.sink_inDegree)\n",
    "df_train_neg['jaccard_in'] = df_train_neg.common_followers/(df_train_neg.source_inDegree + df_train_neg.sink_inDegree)\n",
    "df_test['jaccard_in'] = df_test.common_followers/(df_test.source_inDegree + df_test.sink_inDegree)\n",
    "df_train_pos.isnull().values.any(), df_train_neg.isnull().values.any(), df_test.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preferential Attachment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pos['preferential_attachment_out'] = df_train_pos.source_outDegree * df_train_pos.sink_inDegree\n",
    "df_train_neg['preferential_attachment_out'] = df_train_neg.source_outDegree * df_train_neg.sink_inDegree\n",
    "df_test['preferential_attachment_out'] = df_test.source_outDegree * df_test.sink_inDegree\n",
    "df_train_pos.isnull().values.any(), df_train_neg.isnull().values.any(), df_test.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pos['preferential_attachment_in'] = df_train_pos.source_inDegree * df_train_pos.sink_outDegree\n",
    "df_train_neg['preferential_attachment_in'] = df_train_neg.source_inDegree * df_train_neg.sink_outDegree\n",
    "df_test['preferential_attachment_in'] = df_test.source_inDegree * df_test.sink_outDegree\n",
    "df_train_pos.isnull().values.any(), df_train_neg.isnull().values.any(), df_test.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg = df_train_neg\n",
    "df_pos = df_train_pos\n",
    "df_training = pd.concat([df_pos,df_neg])\n",
    "print(df_training.shape)\n",
    "df_training_x = df_training.drop(['label'], axis = 1)\n",
    "df_training_y = df_training['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_training_x, df_training_y, test_size=0.0,random_state = 42)\n",
    "droppingcolumns = []\n",
    "X_train = X_train.drop(droppingcolumns, axis=1)\n",
    "X_test = X_test.drop(droppingcolumns, axis=1)\n",
    "df_training_x = df_training_x.drop(droppingcolumns, axis=1)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "droppingcolumnsFeatures = ['label']\n",
    "droppingcolumnsFeatures = droppingcolumns + droppingcolumnsFeatures\n",
    "test_data = df_test.drop(droppingcolumnsFeatures, axis=1)\n",
    "test_data = scaler.transform(test_data)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "tuples = [x for x in itertools.product((23,24,25,26),repeat=4)]\n",
    "# tuples = [x for x in itertools.product((7,8,9),repeat=4)]\n",
    "# tuples = [(17,),(17,16),(17,16,15),(17,16,15,14),(17,16,15,14,13),(17,16,15,14,13,12),\n",
    "#           (17,16,15,14,13,12,11),(17,16,15,14,13,12,11,10),(17,16,15,14,13,12,11,10,9),\n",
    "#           (17,16,15,14,13,12,11,10,9,8),(17,16,15,14,13,12,11,10,9,8,7),(17,16,15,14,13,12,11,10,9,8,7,6),\n",
    "#          (17,16,15,14,13,12,11,10,9,8,7,6,5),(17,16,15,14,13,12,11,10,9,8,7,6,5,4),(17,16,15,14,13,12,11,10,9,8,7,6,5,4,3),\n",
    "#          (17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2),(17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1)]\n",
    "print(len(tuples))\n",
    "for tup in tuples:\n",
    "    model = MLPClassifier(hidden_layer_sizes=tup,max_iter=1500, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "    print(tup, ', Accuracy: {:.2f}'.format(model.score(X_test, y_test)), \"AUC: \",\n",
    "          roc_auc_score(y_test, model.predict_proba(X_test)[:,1]),\", Predicted:\", model.predict(test_data).sum(),\n",
    "         \", TP:\",tp,\", FP:\",fp,\", TN:\",tn,\", FN:\",fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes=(17), max_iter=1500, random_state=42)\n",
    "# model = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_test)\n",
    "# y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "# print('Accuracy of classifier on test set: {:.6f}'.format(model.score(X_test, y_test)))\n",
    "# print('AUC of classifier PROB on test set: {:.6f}'.format(roc_auc_score(y_test, model.predict_proba(X_test)[:,1])))\n",
    "# print('AUC of classifier LABEL on test set: {:.6f}'.format(roc_auc_score(y_test, model.predict(X_test))))\n",
    "# tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "# print(\" TP:\",tp,\", FP:\",fp,\", TN:\",tn,\", FN:\",fn)\n",
    "# false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "# print(\"AUC score of classifier on test set: \", auc(false_positive_rate, true_positive_rate))\n",
    "# check_results(y_pred,y_test)\n",
    "predictions = model.predict(test_data)\n",
    "predictions_proba = model.predict_proba(test_data)[:,1]\n",
    "print(predictions.sum(),predictions_proba.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myFields = ['Id', 'Prediction']\n",
    "with open(\"output.csv\",'w', newline='') as resultFile:\n",
    "    writer = csv.DictWriter(resultFile, fieldnames=myFields)\n",
    "    writer.writeheader()\n",
    "    for i in range(len(predictions_proba)):\n",
    "        writer.writerow({'Id' : i+1, 'Prediction': predictions_proba[i]})\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "\n",
    "# Create the RFE object and compute a cross-validated score.\n",
    "svc = LogisticRegression(C=15, max_iter = 500, tol = .0000001, random_state = 42)\n",
    "# classifications\n",
    "rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(2),\n",
    "              scoring='accuracy',verbose=2, n_jobs=-1)\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfecv.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "kepler_mutual_information = mutual_info_classif(kepler_X, kepler_y)\n",
    "\n",
    "plt.subplots(1, figsize=(26, 1))\n",
    "sns.heatmap(kepler_mutual_information[:, np.newaxis].T, cmap='Blues', cbar=False, linewidths=1, annot=True)\n",
    "plt.yticks([], [])\n",
    "plt.gca().set_xticklabels(kepler.columns[1:], rotation=45, ha='right', fontsize=12)\n",
    "plt.suptitle(\"Kepler Variable Importance (mutual_info_classif)\", fontsize=18, y=1.2)\n",
    "plt.gcf().subplots_adjust(wspace=0.2)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "models['Random Forest'] = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "models['Logistic Regression'] = LogisticRegression()\n",
    "models['Multilayer Perceptron'] = MLPClassifier()\n",
    "models['SVM'] = svm.SVC()\n",
    "models['Gaussian NB'] = GaussianNB()\n",
    "models['Adaboost Classifier'] = AdaBoostClassifier()\n",
    "models['KNN'] = KNeighborsClassifier(3)\n",
    "models['Gaussian Process Classifier'] = GaussianProcessClassifier(1.0 * RBF(1.0))\n",
    "models['Decision Tree Classifier'] = DecisionTreeClassifier(max_depth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_depth' : [4,6,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "clf = GridSearchCV(estimator=RandomForestClassifier(random_state=42), \n",
    "                   param_grid=param_grid, n_jobs=-1, verbose = 2)\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "print(\"Best score: %0.4f\" % clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = roc_auc_score(y_test, model.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat([df_train_pos_sample, df_train_neg_sample, df_test])\n",
    "df = pd.concat([df_train_pos, df_train_neg, df_test])\n",
    "# df = pd.concat([df_test, df_train_pos_sample])\n",
    "# df = df[[ 'sink_inDegree', 'sink_outDegree', 'label']]\n",
    "# df = df[['source_inDegree','source_outDegree', 'label']]\n",
    "# df = df[['sink_pr', 'source_pr', 'label']]\n",
    "df = df[['common_followers','common_followees', 'triadic_closure','followback', 'label']]\n",
    "# df = df[['aa', 'outDegreeRatio','outInRatio', 'label']]\n",
    "# df = df[['common_neighbors','jaccard_in', 'jaccard_out','preferential_attachment_out', 'preferential_attachment_in', 'label']]\n",
    "sns.pairplot(df.astype(float), height=4.5, hue = 'label')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
